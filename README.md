

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim:
To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

## AI Tools Required: 
ChatGPT (GPT-5 model) or equivalent large language model.
Text editor/word processor for documentation.
# Explanation: 

### Define the Two Prompt Types:

Write a basic Prompt: Clear, detailed, and structured prompts that give specific instructions or context to guide the model.
Based on that pattern type refined the prompt and submit that with AI tool.
Get the ouput and write the report.

## Prepare Multiple Test Scenarios:
Select various scenarios such as:
Generating a creative story.
Answering a factual question.
Summarizing an article or concept.
Providing advice or recommendations.
Or Any other test scenario
For each scenario, create both a naïve and a basic prompt. Ensure each pair of prompts targets the same task but with different levels of structure.
## Run Experiments with ChatGPT:
Input the naïve prompt for each scenario and record the generated response.
Then input the corresponding basic prompt and capture that response.
Repeat this process for all selected scenarios to gather a full set of results.
## Evaluate Responses : 
Compare how ChatGPT performs when given naïve versus basic prompts and analyze the output based on Quality,Accuracy and Depth. Also analyse does ChatGPT consistently provide better results with basic prompts? Are there scenarios where naïve prompts work equally well?
Deliverables:
A table comparing ChatGPT's responses to naïve and basic prompts across all scenarios.
Analysis of how prompt clarity impacts the quality, accuracy, and depth of ChatGPT’s outputs.
Summary of findings with insights on how to structure prompts for optimal results when using ChatGPT.
 ## Types of Prompts:
 
 1. Naïve Prompt (Broad/Unstructured):
 Short, vague, or general instruction with little to no context.
 Example: “Tell me about AI.”
2. Basic Prompt (Clear/Structured/Refined):
 Detailed and specific instruction with clear context and scope.
 Example: “Explain Artificial Intelligence in simple terms, focusing on its applications in daily
 life such as healthcare, education, and business.”
 ## Methodology:
 
 1. Selected 4 test scenarios:
 Generating a creative story
 Answering a factual question
 Summarizing a concept
 Providing advice/recommendations
 2. For each scenario:
 Prepared a naïve prompt (unstructured).
 Prepared a basic prompt (structured).
 Recorded ChatGPT’s responses.
 3. Evaluated responses on:
 Quality (clarity, coherence, language use)
 Accuracy (correctness of facts, alignment with task)
 Depth (detail, completeness, richness of information).
## Test Scenarios and Responses:
 
## Scenario 1: Creative Story
 
## Naïve Prompt: “Write a story.”
 
## Output:

 <img width="988" height="332" alt="image" src="https://github.com/user-attachments/assets/961476ca-2593-438e-94d1-8f0770fbc2d9" />

## Output :

<img width="987" height="666" alt="image" src="https://github.com/user-attachments/assets/2f671a16-0acc-42b9-92fb-facf8b97f729" />

## Scenario 2: Factual Question

## Naïve Prompt: “What is quantum entanglement?”

## Output :

<img width="993" height="650" alt="image" src="https://github.com/user-attachments/assets/fb603503-f7bf-48b3-96bd-fb0e30d4b6bb" />

## Basic Prompt: 
“Explain quantum entanglement in simple terms for beginners, using a real-world
 analogy. Keep the explanation under 120 words.”
 
## Output:
 
 <img width="1009" height="420" alt="image" src="https://github.com/user-attachments/assets/58fe7cbe-ad29-4ad9-861e-284543472746" />
 
## Scenario 3: Summarization

## Naïve Prompt: “Summarize climate change.”

## Output :
 
 <img width="990" height="537" alt="image" src="https://github.com/user-attachments/assets/77509765-461e-4952-b398-c7e142fa2f88" />
 
## Basic Prompt:
“Summarize climate change in under 100 words, focusing on its causes, major
 effects, and one possible solution.”
 
## Output:

<img width="992" height="406" alt="image" src="https://github.com/user-attachments/assets/432dca7d-847a-42a8-9453-866b2869e844" />

## Scenario 4: Advice/Recommendation

## Naïve Prompt: “Give me career advice.”

## Output :

<img width="994" height="610" alt="image" src="https://github.com/user-attachments/assets/ac32f849-3586-4275-9df9-5dc769ad6898" />

## Basic Prompt: “Provide career advice for a college student interested in Artificial Intelligence,
 suggesting relevant skills, learning resources, and future opportunities in the field.”
## Output :
 
 Nice — AI is a great field to get into. Here’s a clear, beginner-friendly plan with the skills to
 learn, concrete resources, and the career paths you can aim for.
 What to learn (core skills)
 Programming: Python (numpy, pandas).
 Math basics: Linear algebra, probability, calculus (for ML intuition).
 Machine learning: Supervised/unsupervised learning, model evaluation.
 Deep learning: Neural nets, CNNs, RNNs/transformers.
 Data skills: Data cleaning, feature engineering, SQL.
 Tools & frameworks: PyTorch or TensorFlow; Hugging Face for LLMs.
 Software engineering: Git, testing, APIs, containers.
 MLOps & deployment: Model serving, monitoring, cloud basics.
 Ethics & safety: Responsible AI, bias awareness.
 Concrete learning path (beginner → practical)
 1. Foundations (1–3 months): Python + basic math.
 2. Core ML (2–3 months): Intro ML course and small projects.
 3. Deep learning (2–4 months): Practical DL + build image/NLP models.
 4. Applied projects & portfolio (ongoing): Kaggle challenges, GitHub repos.
5. Advanced / Specialize: LLMs, computer vision, RL, MLOps, or research.
 Recommended resources (free/paid)
 Intro ML / Foundations: Andrew Ng’s Machine Learning/Machine Learning Specialization.
 (Coursera)
 Practical deep learning: fast.ai’s Practical Deep Learning for Coders. (
 Practical Deep Learning
 for Coders)
 Hands-on practice & competitions: Kaggle (notebooks + competitions). (
 Kaggle)
 Modern NLP & LLMs: Hugging Face learn & community tutorials. (
 Hugging Face)
 Job market trends & demand: LinkedIn/industry reports showing rising AI hiring — good sign
 for opportunities. (
 LinkedIn Economic Graph)
 Build experience (what to show employers)
 3–6 small projects (end-to-end): dataset → model → evaluation → deployment (demo website
 or API).
 One medium project in your interest area (NLP/vision/robotics).
 Kaggle notebooks or GitHub code with clear READMEs.
 Internships, research assistant roles, or open-source contributions.
 Career roles & future opportunities
 ML Engineer / Software Engineer (AI): production models, data pipelines.
 Data Scientist / Analyst: business insights + models.
 Research Scientist: theory and novel models (requires deep math + publications).
 MLOps / Site Reliability for ML: deployment, monitoring, scaling.
 AI Product / Ethics / Policy: bridge between tech, users, and governance.
 Prompt engineer / LLM engineer: building products using LLMs and agents.
 Quick tips
 Prioritize doing — build projects from day one.
 Learn one framework deeply (PyTorch recommended for research/practicality).
 Network (LinkedIn, GitHub, Hugging Face forums, Kaggle).
 Read papers selectively (start with accessible ones) and reproduce results.
 Keep ethics front-and-center — it matters to employers and society.
 If you want, I can:
 Draft a 6-month learning schedule tailored to your current skills, or
 Recommend 3 project ideas (beginner → intermediate → advanced) you can build and
 showcase. Which would help most?


 ## Results Table:
 
 <img width="701" height="796" alt="image" src="https://github.com/user-attachments/assets/44cfd19e-56a8-44b4-ba42-34d154e37d16" />

 
 ## Analysis:
 
 ## Naïve Prompts:
 Often produced vague, generic, or overly broad answers.
 Limited detail and sometimes less audience-appropriate.
 
 ## Basic Prompts:
 Produced clearer, structured, more detailed, and more relevant answers.
 Better alignment with the user’s expectations.
 Higher quality in terms of readability and usefulness.
 
 ## Consistency:
 Across all scenarios, basic prompts consistently outperformed naïve prompts.
 However, in very simple factual queries (e.g., “What is 2+2?”), naïve prompts can still
 produce correct results.
 
<img width="630" height="382" alt="image" src="https://github.com/user-attachments/assets/bfb9d233-9dac-4998-a1ee-d54066793622" />

 ## Summary of Findings
 
 1. Prompt clarity directly impacts the quality, accuracy, and depth of AI-generated responses.
 2. Naïve prompts → Generic, vague, sometimes confusing results.
 3. Basic prompts → Focused, structured, more informative, and task-specific outputs.
 4. For creative, advisory, or explanatory tasks, refined prompts are essential for optimal results.
 5. Good prompt design is a skill: the more specific and structured the prompt, the better the AI
 performs.

# RESULT: 
The prompt for the above said problem executed successfully
